import streamlit as st
from PIL import Image
import io
import numpy as np
import wave
import tempfile
import os
import platform
from datetime import datetime
import openai

# --- 0. ê¸°ë³¸ ì„¤ì • ë° í•¨ìˆ˜ ì •ì˜ ---

# í”Œë«í¼ í™•ì¸ (ë¡œì»¬/í´ë¼ìš°ë“œ êµ¬ë¶„)
IS_LOCAL = platform.system() != "Linux"
if IS_LOCAL:
    try:
        import sounddevice as sd
    except Exception as e:
        st.error(f"Sounddevice ë¡œë“œ ì‹¤íŒ¨. ë§ˆì´í¬ ì‚¬ìš©ì´ ë¶ˆê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: {e}")
        IS_LOCAL = False

# OpenAI API í‚¤ ì„¤ì •
# ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” st.secrets ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
# openai.api_key = st.secrets["OPENAI_API_KEY"] 
try:
    openai.api_key = os.getenv("OPENAI_API_KEY")
    if openai.api_key is None:
        st.error("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
except Exception as e:
    st.error(f"API í‚¤ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# --- Helper Functions (GPT, Audio, Avatar) ---

# gpt_summarizer.pyì˜ í•¨ìˆ˜ë“¤
def summarize_text(text: str) -> str:
    prompt = f"Summarize the following interview transcript concisely in one or two sentences in Korean:\n\n{text}"
    try:
        response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "system", "content": "You are a helpful summarization expert."}, {"role": "user", "content": prompt}], max_tokens=300, temperature=0.5)
        return response.choices[0].message.content.strip()
    except Exception as e: return f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

def create_final_video_prompt(family_name: str, theme: str, transcript: str) -> str:
    prompt = f"""You are a creative and empathetic video director. Your task is to create a detailed, scene-by-scene storyboard prompt in English for an AI video generator.
    **Family Name:** {family_name}
    **Chosen Video Theme:** {theme}
    **Full Interview Transcript (in Korean):**\n---\n{transcript}\n---
    Based on all the information above, generate a rich, descriptive prompt that outlines a short video. Describe scenes, camera angles, emotions, and overall style to bring the family's story to life.
    Example: "Scene 1: A warm, sunlit kitchen. Close-up on the laughing face of '{family_name}' as they share a story. Style: nostalgic, warm, cinematic."
    """
    try:
        response = openai.chat.completions.create(model="gpt-4o", messages=[{"role": "system", "content": "You are a professional video director creating prompts for an AI video generator."}, {"role": "user", "content": prompt}], max_tokens=500, temperature=0.7)
        return response.choices[0].message.content.strip()
    except Exception as e: return f"í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# ì˜¤ë””ì˜¤ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
def record_audio(duration_sec=10, fs=16000):
    st.info(f"{duration_sec}ì´ˆê°„ ì¸í„°ë·° ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    try:
        audio_data = sd.rec(int(duration_sec * fs), samplerate=fs, channels=1, dtype='int16')
        sd.wait()
        st.success("ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return audio_data.flatten()
    except Exception as e:
        st.error(f"ì˜¤ë””ì˜¤ ë…¹ìŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë§ˆì´í¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”. ì˜¤ë¥˜: {e}")
        return None

def numpy_to_wav_bytes(audio_np, fs=16000):
    buffer = io.BytesIO()
    with wave.open(buffer, 'wb') as wf:
        wf.setnchannels(1); wf.setsampwidth(2); wf.setframerate(fs); wf.writeframes(audio_np.tobytes())
    buffer.seek(0)
    return buffer

def transcribe_and_create_prompt(audio_input, family_name, theme):
    tmp_path = None
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_input.getvalue())
            tmp_path = tmp_file.name
        
        with open(tmp_path, "rb") as audio_file:
            result = openai.audio.transcriptions.create(model="whisper-1", file=audio_file)
        transcript = result.text
        
        summary = summarize_text(transcript)
        final_prompt = create_final_video_prompt(family_name, theme, transcript)
        return transcript, summary, final_prompt
    except Exception as e:
        st.error(f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "", "", ""
    finally:
        if tmp_path and os.path.exists(tmp_path): os.remove(tmp_path)

# ì•„ë°”íƒ€ ê´€ë ¨ í•¨ìˆ˜ (ì‹¤ì œ êµ¬í˜„ì€ ë³„ë„ íŒŒì¼ì—)
def extract_face(image_pil):
    # DUMMY: ì‹¤ì œ ì–¼êµ´ ì¶”ì¶œ ë¡œì§
    return image_pil.resize((256, 256))

def generate_avatar(prompt):
    # DUMMY: ì‹¤ì œ ì•„ë°”íƒ€ ìƒì„± ë¡œì§
    return Image.new('RGB', (512, 512), color = 'red')

def create_video_from_text_and_image(full_prompt, image_path):
    st.info(f"ì˜ìƒ ìƒì„± ì¤‘...\n\nğŸ§¾ í”„ë¡¬í”„íŠ¸: {full_prompt}\nğŸ–¼ï¸ ì´ë¯¸ì§€ ê²½ë¡œ: {image_path}")
    st.success("âœ… (ì˜ˆì‹œ) ì˜ìƒ ìƒì„± ì™„ë£Œ! ì‹¤ì œ ì˜ìƒ ìƒì„± ê¸°ëŠ¥ì€ ì¶”í›„ ì—°ë™ë©ë‹ˆë‹¤.")


# --- ì„¸ì…˜ ìƒíƒœ ë° UI ì´ˆê¸°í™” ---
st.title("ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ê°€ì¡± ì´ì•¼ê¸° AI ì˜ìƒ ë§Œë“¤ê¸°")

if 'step' not in st.session_state:
    st.session_state.step = "select_theme"
# ë‹¤ë¥¸ ì„¸ì…˜ ë³€ìˆ˜ë“¤ë„ ì´ˆê¸°í™”
default_states = {
    "family_name": "", "selected_theme": "", "saved_image_path": None,
    "transcript": "", "summary": "", "final_prompt": None
}
for key, value in default_states.items():
    if key not in st.session_state:
        st.session_state[key] = value

os.makedirs("image_storage", exist_ok=True) # ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„±

# --- 1ë‹¨ê³„: í…Œë§ˆ ì„ íƒ ---
if st.session_state.step == "select_theme":
    st.header("1ë‹¨ê³„: ì˜ìƒ í…Œë§ˆ ì •í•˜ê¸°")
    family_name = st.text_input("ê°€ì¡±ì˜ í˜¸ì¹­ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì‚¬ë‘í•˜ëŠ” ìš°ë¦¬ ê°€ì¡±")
    
    interview_questions = { "ìš°ë¦¬ì˜ í‰ë²”í•˜ì§€ë§Œ ì†Œì¤‘í•œ ì¼ìƒ": [], "í•¨ê»˜ ë– ë‚¬ë˜ ì¦ê±°ìš´ ì—¬í–‰ì˜ ì¶”ì–µ": [], "íŠ¹ë³„í•œ ë‚ ì˜ í–‰ë³µí–ˆë˜ ìˆœê°„ë“¤ (ìƒì¼, ëª…ì ˆ ë“±)": [], "ì•„ì´ë“¤ì˜ ì‚¬ë‘ìŠ¤ëŸ¬ìš´ ì„±ì¥ ê¸°ë¡": [], "ë‹¤ì‹œ ë´ë„ ì›ƒìŒì´ ë‚˜ëŠ” ìš°ë¦¬ ê°€ì¡±ì˜ ì¬ë¯¸ìˆëŠ” ìˆœê°„": [], "ì„œë¡œì—ê²Œ ì „í•˜ëŠ” ì‚¬ë‘ê³¼ ê°ì‚¬ì˜ ë©”ì‹œì§€": [] }
    themes = list(interview_questions.keys())
    selected_theme = st.radio("ì–´ë–¤ í…Œë§ˆì˜ ì˜ìƒì„ ë§Œë“¤ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?", themes, key="theme_radio")
    
    if st.button("ë‹¤ìŒ ë‹¨ê³„ë¡œ: ì–¼êµ´ ì‚¬ì§„ ì…ë ¥ â–¶ï¸"):
        if not family_name:
            st.warning("ê°€ì¡±ì˜ í˜¸ì¹­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            st.session_state.family_name = family_name
            st.session_state.selected_theme = selected_theme
            st.session_state.step = "capture_avatar"
            st.rerun()

# --- 2ë‹¨ê³„: ì–¼êµ´ ì‚¬ì§„(ì•„ë°”íƒ€) ì…ë ¥ ---
elif st.session_state.step == "capture_avatar":
    st.header("2ë‹¨ê³„: ì˜ìƒì— ì‚¬ìš©í•  ì–¼êµ´ ì‚¬ì§„ ì…ë ¥")
    st.info(f"**ê°€ì¡± í˜¸ì¹­:** {st.session_state.family_name} / **í…Œë§ˆ:** {st.session_state.selected_theme}")

    tab1, tab2 = st.tabs(["ğŸ“¸ ì¹´ë©”ë¼ ì´¬ì˜", "ğŸ–¼ï¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ"])
    image_pil = None
    with tab1:
        if IS_LOCAL:
            image_file = st.camera_input("ì•„ë°”íƒ€ìš© ì‚¬ì§„ì„ ì°ì–´ë³´ì„¸ìš”")
            if image_file: image_pil = Image.open(image_file)
        else:
            st.warning("í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œëŠ” ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ì—…ë¡œë“œë¥¼ ì´ìš©í•´ì£¼ì„¸ìš”.")
    with tab2:
        uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])
        if uploaded_file: image_pil = Image.open(uploaded_file)
    
    if image_pil:
        st.image(image_pil, caption="ğŸ“· ì›ë³¸ ì´ë¯¸ì§€", use_container_width=True)
        with st.spinner("ì–¼êµ´ì„ ì¸ì‹í•˜ê³  ì•„ë°”íƒ€ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
            face_img = extract_face(image_pil)
            if face_img is None:
                st.error("ğŸ˜¢ ì–¼êµ´ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‹œë„í•´ì£¼ì„¸ìš”.")
            else:
                st.image(face_img, caption="âœ‚ï¸ ì¶”ì¶œëœ ì–¼êµ´", width=256)
                # DUMMY ì•„ë°”íƒ€ ìƒì„± ë¡œì§, ì‹¤ì œë¡œëŠ” API í˜¸ì¶œ
                avatar_img = generate_avatar("dummy prompt") 
                st.image(avatar_img, caption="ğŸ–¼ï¸ ìƒì„±ëœ AI ì•„ë°”íƒ€", use_container_width=True)
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                save_path = f"image_storage/avatar_{timestamp}.jpg"
                avatar_img.save(save_path)
                st.session_state.saved_image_path = save_path
                st.success(f"âœ… ì•„ë°”íƒ€ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")

    if st.session_state.saved_image_path:
        if st.button("ë‹¤ìŒ ë‹¨ê³„ë¡œ: ì¸í„°ë·° ì§ˆë¬¸ í™•ì¸ â–¶ï¸"):
            st.session_state.step = "show_questions"
            st.rerun()

# --- 3ë‹¨ê³„: ì¸í„°ë·° ì§ˆë¬¸ í™•ì¸ ---
elif st.session_state.step == "show_questions":
    st.header("3ë‹¨ê³„: ì¸í„°ë·° ì§ˆë¬¸ í™•ì¸")
    st.info(f"**ê°€ì¡± í˜¸ì¹­:** {st.session_state.family_name} / **í…Œë§ˆ:** {st.session_state.selected_theme}")
    st.markdown("ì•„ë˜ ì§ˆë¬¸ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì¡±ê³¼ ììœ ë¡­ê²Œ ëŒ€í™”í•˜ë©° ì¸í„°ë·°ë¥¼ ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
    
    # ì‹¤ì œ ì§ˆë¬¸ ëª©ë¡ í‘œì‹œ
    # for i, q in enumerate(interview_questions[st.session_state.selected_theme]):
    #     st.markdown(f"**Q{i+1}.** {q}")

    if st.button("âœ… ì¸í„°ë·° ì¤€ë¹„ ì™„ë£Œ! ë…¹ìŒ ì‹œì‘í•˜ê¸° â–¶ï¸"):
        st.session_state.step = "record_interview"
        st.rerun()

# --- 4ë‹¨ê³„: ì¸í„°ë·° ë…¹ìŒ ë° í”„ë¡¬í”„íŠ¸ ìƒì„± ---
elif st.session_state.step == "record_interview":
    st.header("4ë‹¨ê³„: ì¸í„°ë·° ë…¹ìŒ ë° AI í”„ë¡¬í”„íŠ¸ ìƒì„±")
    st.info(f"**ê°€ì¡± í˜¸ì¹­:** {st.session_state.family_name} / **í…Œë§ˆ:** {st.session_state.selected_theme}")
    
    record_duration = st.slider("ë…¹ìŒí•  ì‹œê°„(ì´ˆ)ì„ ì„ íƒí•˜ì„¸ìš”", 10, 180, 30)
    if IS_LOCAL and st.button(f"ğŸ™ï¸ {record_duration}ì´ˆê°„ ì¸í„°ë·° ë…¹ìŒ ì‹œì‘"):
        audio_np = record_audio(duration_sec=record_duration)
        if audio_np is not None:
            wav_bytes = numpy_to_wav_bytes(audio_np)
            st.audio(wav_bytes, format="audio/wav")
            with st.spinner("ìŒì„±ì„ ë¶„ì„í•˜ê³  ì˜ìƒ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                st.session_state.transcript, st.session_state.summary, st.session_state.final_prompt = \
                    transcribe_and_create_prompt(wav_bytes, st.session_state.family_name, st.session_state.selected_theme)

    uploaded_audio_file = st.file_uploader("ë˜ëŠ” ë…¹ìŒëœ ì¸í„°ë·° íŒŒì¼(.wav/.mp3)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["wav", "mp3", "m4a"])
    if uploaded_audio_file:
        st.audio(uploaded_audio_file)
        with st.spinner("ìŒì„±ì„ ë¶„ì„í•˜ê³  ì˜ìƒ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
            audio_bytes_io = io.BytesIO(uploaded_audio_file.getvalue())
            st.session_state.transcript, st.session_state.summary, st.session_state.final_prompt = \
                transcribe_and_create_prompt(audio_bytes_io, st.session_state.family_name, st.session_state.selected_theme)
    
    if st.session_state.final_prompt:
        st.success("âœ¨ AI í”„ë¡¬í”„íŠ¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.text_area("ğŸ“ ì¸í„°ë·° ì „ì²´ ë‚´ìš©", st.session_state.transcript, height=150)
        st.text_area("ğŸ” í•œ ì¤„ ìš”ì•½", st.session_state.summary, height=50)
        if st.button("ë‹¤ìŒ ë‹¨ê³„ë¡œ: ìµœì¢… í™•ì¸ ë° ì˜ìƒ ìƒì„± â–¶ï¸"):
            st.session_state.step = "create_video"
            st.rerun()

# --- 5ë‹¨ê³„: ìµœì¢… í™•ì¸ ë° ì˜ìƒ ìƒì„± ---
elif st.session_state.step == "create_video":
    st.header("5ë‹¨ê³„: ìµœì¢… í™•ì¸ ë° ì˜ìƒ ìƒì„±")
    
    image_path = st.session_state.saved_image_path
    final_prompt = st.session_state.final_prompt

    if image_path and final_prompt:
        st.info("ì•„ë˜ ì •ë³´ë¡œ ìµœì¢… ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.")
        st.image(image_path, caption="ğŸ¨ ìµœì¢… ì˜ìƒìš© ì•„ë°”íƒ€ ì´ë¯¸ì§€")
        st.text_area("ğŸ¬ ìµœì¢… ì˜ìƒ AI í”„ë¡¬í”„íŠ¸", final_prompt, height=200)
        if st.button("ğŸï¸ ì´ ë‚´ìš©ìœ¼ë¡œ ì˜ìƒ ë§Œë“¤ê¸°", type="primary"):
            with st.spinner("ì˜ìƒì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... (1~2ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                create_video_from_text_and_image(final_prompt, image_path)
    else:
        st.error("ì˜ìƒ ìƒì„±ì— í•„ìš”í•œ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.")

# --- ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸° ë²„íŠ¼ ---
if st.session_state.step != "select_theme":
    if st.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        # ëª¨ë“  ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°ê°’ìœ¼ë¡œ ë¦¬ì…‹
        for key, value in default_states.items():
            st.session_state[key] = value
        st.session_state.step = "select_theme"
        st.rerun()