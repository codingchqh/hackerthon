# app.py (ì´ì „ ì½”ë“œì™€ ë™ì¼)

import streamlit as st
from PIL import Image
import io
import numpy as np
import wave
import whisper
import tempfile
import os
import platform
from datetime import datetime

# avatar_generator ëª¨ë“ˆì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from avatar_create.avatar_generator import generate_avatar_image, download_image_from_url

# camera/face_capture.pyì— extract_face í•¨ìˆ˜ê°€ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
from camera.face_capture import extract_face

# summarizer/gpt_summarizer.pyì— summarize_text, generate_video_script í•¨ìˆ˜ê°€ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
from summarizer.gpt_summarizer import summarize_text, generate_video_script

# --- í”Œë«í¼ í™•ì¸ (ë¡œì»¬/í´ë¼ìš°ë“œ êµ¬ë¶„) ---
IS_LOCAL = platform.system() != "Linux"
if IS_LOCAL:
    import sounddevice as sd

# --- ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜ ---
def load_model():
    """Whisper ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    return whisper.load_model("base")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "model" not in st.session_state:
    st.session_state.model = None
if "saved_image_path" not in st.session_state:
    st.session_state["saved_image_path"] = None
if "video_prompt" not in st.session_state:
    st.session_state["video_prompt"] = None
if "script" not in st.session_state:
    st.session_state["script"] = None

# --- UI ì„¤ì • ---
st.set_page_config(page_title="ê³µê° on(æº«)", layout="centered")
st.title("ğŸ“¸ ê³µê° on(æº«)")

# --- 0ï¸âƒ£ ëª¨ë¸ ë¡œë“œ ë²„íŠ¼ ---
if st.session_state.model is None:
    if st.button("ëª¨ë¸ ë¡œë“œí•˜ê¸°"):
        with st.spinner("ëª¨ë¸ì„ ë¡œë”©ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            st.session_state.model = load_model()
        st.success("âœ… ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
else:
    st.info("âœ… ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")

# --- ë””ë ‰í† ë¦¬ ìƒì„± ---
os.makedirs("image", exist_ok=True)

# --- 1ï¸âƒ£ ì‚¬ì§„ ì…ë ¥: ì¹´ë©”ë¼ ì´¬ì˜ ë˜ëŠ” ì´ë¯¸ì§€ ì—…ë¡œë“œ ---
st.header("1ï¸âƒ£ ì–¼êµ´ ì´ë¯¸ì§€ ì…ë ¥ ë° ì•„ë°”íƒ€ ìƒì„±")

tab1, tab2 = st.tabs(["ğŸ“¸ ì¹´ë©”ë¼ ì´¬ì˜", "ğŸ–¼ï¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ"])
image_pil = None # ì‚¬ìš©ìê°€ ì„ íƒí•œ ì›ë³¸ ì´ë¯¸ì§€ (PIL.Image.Image ê°ì²´)

with tab1:
    image_file = st.camera_input("ì•„ë°”íƒ€ìš© ì‚¬ì§„ì„ ì°ì–´ë³´ì„¸ìš”")
    if image_file:
        image_pil = Image.open(image_file)
        st.image(image_pil, caption="ğŸ“· ì´¬ì˜ëœ ì›ë³¸ ì´ë¯¸ì§€", use_container_width=True)

with tab2:
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (jpg/png)", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        image_pil = Image.open(uploaded_file)
        st.image(image_pil, caption="ğŸ–¼ï¸ ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)

# ì´ë¯¸ì§€ê°€ ì…ë ¥ë˜ì—ˆì„ ë•Œë§Œ ì²˜ë¦¬
if image_pil:
    face_img = None # ì¶”ì¶œëœ ì–¼êµ´ ì´ë¯¸ì§€ (PIL.Image.Image ê°ì²´)
    try:
        face_img = extract_face(image_pil) # camera.face_capture ëª¨ë“ˆì˜ í•¨ìˆ˜ í˜¸ì¶œ
    except Exception as e:
        st.error(f"ì–¼êµ´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        face_img = None # ì˜¤ë¥˜ ë°œìƒ ì‹œ Noneìœ¼ë¡œ ì„¤ì •

    if face_img is None:
        st.error("ğŸ˜¢ ì–¼êµ´ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‹œë„í•´ì£¼ì„¸ìš”.")
    else:
        st.image(face_img, caption="âœ‚ï¸ ì¶”ì¶œëœ ì–¼êµ´", width=256) # ì¶”ì¶œëœ ì–¼êµ´ í‘œì‹œ

        # ì•„ë°”íƒ€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì„¤ì • (í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸)
        avatar_generation_prompt = "A friendly and expressive cartoon avatar, digital art style"

        avatar_urls = [] # generate_avatar_imageê°€ ë°˜í™˜í•  URL ë¦¬ìŠ¤íŠ¸
        try:
            # generate_avatar_image í•¨ìˆ˜ í˜¸ì¶œ (ìˆ˜ì •ëœ ì´ë¦„)
            # DALL-EëŠ” í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œ ë°›ìœ¼ë¯€ë¡œ, face_imgê°€ ì•„ë‹ˆë¼ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
            avatar_urls = generate_avatar_image(prompt=avatar_generation_prompt, n_images=1)
        except Exception as e:
            st.error(f"ì•„ë°”íƒ€ ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            avatar_urls = []

        avatar_img = None # ìµœì¢… ì•„ë°”íƒ€ ì´ë¯¸ì§€ (PIL.Image.Image ê°ì²´)
        if avatar_urls:
            print("ìƒì„±ëœ ì•„ë°”íƒ€ ì´ë¯¸ì§€ URL:", avatar_urls[0])
            try:
                # ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ í˜¸ì¶œ
                avatar_img = download_image_from_url(avatar_urls[0])
            except Exception as e:
                st.error(f"ì•„ë°”íƒ€ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                avatar_img = None
        else:
            st.error("ğŸ˜¢ ì•„ë°”íƒ€ ì´ë¯¸ì§€ URL ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. OpenAI API ì„¤ì • ë˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            avatar_img = None # URLì´ ì—†ìœ¼ë©´ ì´ë¯¸ì§€ë„ ì—†ìŒ

        # avatar_imgê°€ ìœ íš¨í•œ Image ê°ì²´ì¼ ë•Œë§Œ í‘œì‹œ ë° ì €ì¥
        if avatar_img is not None and isinstance(avatar_img, Image.Image):
            st.image(avatar_img, caption="ğŸ–¼ï¸ ìƒì„±ëœ AI ì•„ë°”íƒ€", use_container_width=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_path = f"image/avatar_{timestamp}.jpg"
            try:
                avatar_img.save(save_path)
                st.success(f"âœ… ì•„ë°”íƒ€ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")
                st.session_state["saved_image_path"] = save_path
            except Exception as e:
                st.error(f"ì•„ë°”íƒ€ ì´ë¯¸ì§€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.warning("ì•„ë°”íƒ€ ì´ë¯¸ì§€ë¥¼ í‘œì‹œí•˜ê±°ë‚˜ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì´ë¯¸ì§€ ìƒì„±/ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨).")


# --- 2ï¸âƒ£ ì´ë¦„/ìƒë…„ ì…ë ¥ ë° í”„ë¡¬í”„íŠ¸ ìƒì„± ---
st.title("ë§ì¶¤í˜• ì˜ìƒ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ğŸ¬")
name = st.text_input("ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")
birth_year = st.number_input("íƒœì–´ë‚œ ë…„ë„ë¥¼ ì…ë ¥í•˜ì„¸ìš”", min_value=1900, max_value=datetime.now().year, step=1)

def get_age(birth_year):
    """ìƒë…„ì›”ì¼ë¡œ ë‚˜ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    return datetime.now().year - birth_year

if st.button("í”„ë¡¬í”„íŠ¸ ìƒì„±"):
    if not name:
        st.warning("ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        age = get_age(birth_year)
        st.write(f"ì•ˆë…•í•˜ì„¸ìš”, {name}ë‹˜! í˜„ì¬ ë‚˜ì´ëŠ” {age}ì„¸ì…ë‹ˆë‹¤.")
        # ë‚˜ì´ì— ë”°ë¥¸ ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ ìƒì„±
        if age < 20:
            prompt = f"{name}ë‹˜ì˜ ì–´ë¦° ì‹œì ˆ ëª¨ìŠµì„ ë‹´ì€ ë°ê³  í™œê¸°ì°¬ ì˜ìƒ"
        elif age < 40:
            prompt = f"{name}ë‹˜ì˜ ì Šê³  ì—­ë™ì ì¸ ëª¨ìŠµì„ ë‹´ì€ ì„¸ë ¨ëœ ì˜ìƒ"
        elif age < 60:
            prompt = f"{name}ë‹˜ì˜ ì„±ìˆ™í•˜ê³  ì•ˆì •ëœ ëª¨ìŠµì„ ë‹´ì€ ë”°ëœ»í•œ ì˜ìƒ"
        else:
            prompt = f"{name}ë‹˜ì˜ ì¸ìƒì˜ ì§€í˜œì™€ ê²½í—˜ì„ ë‹´ì€ ê°ë™ì ì¸ ì˜ìƒ"
        st.info(f"ìƒì„±ëœ ì˜ìƒ í”„ë¡¬í”„íŠ¸:\n\n{prompt}")
        st.session_state["video_prompt"] = prompt

# --- 3ï¸âƒ£ ìŒì„± ë…¹ìŒ ë° Whisper ì „ì‚¬ ---

def record_audio(duration_sec=5, fs=16000, device=None):
    """ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ë…¹ìŒí•©ë‹ˆë‹¤."""
    if not IS_LOCAL:
        st.error("âš ï¸ ë¡œì»¬ì—ì„œë§Œ ë…¹ìŒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œë¥¼ ì´ìš©í•´ì£¼ì„¸ìš”.")
        return None
    
    if st.session_state.model is None:
        st.warning("Whisper ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return None

    try:
        st.info(f"{duration_sec}ì´ˆê°„ ë…¹ìŒ ì‹œì‘...")
        # sounddeviceê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        audio = sd.rec(int(duration_sec * fs), samplerate=fs, channels=1, dtype='int16', device=device)
        sd.wait()
        st.success("ë…¹ìŒ ì™„ë£Œ!")
        return audio.flatten()
    except Exception as e:
        st.error(f"ì˜¤ë””ì˜¤ ë…¹ìŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def numpy_to_wav_bytes(audio_np, fs=16000):
    """Numpy ë°°ì—´ì„ WAV í˜•ì‹ì˜ BytesIO ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    buffer = io.BytesIO()
    with wave.open(buffer, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2) # 16-bit audio
        wf.setframerate(fs)
        wf.writeframes(audio_np.tobytes())
    buffer.seek(0)
    return buffer

def transcribe_audio(model, audio_input):
    """ì˜¤ë””ì˜¤ë¥¼ Whisper ëª¨ë¸ë¡œ ì „ì‚¬í•˜ê³  ìš”ì•½ ë° ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    tmp_path = None
    try:
        # Streamlit uploaded_file ê°ì²´ëŠ” BytesIOì™€ ìœ ì‚¬í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤.
        # BytesIOë‚˜ ì—…ë¡œë“œëœ íŒŒì¼ ê°ì²´ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ Whisper ëª¨ë¸ì— ì „ë‹¬í•©ë‹ˆë‹¤.
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            audio_input.seek(0) # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ì´ë™ (ì¤‘ìš”!)
            tmp_file.write(audio_input.read()) # ì˜¤ë””ì˜¤ ì…ë ¥ì˜ ë‚´ìš©ì„ ì½ì–´ ì„ì‹œ íŒŒì¼ì— ì”ë‹ˆë‹¤.
            tmp_path = tmp_file.name

        result = model.transcribe(tmp_path)
        transcript = result["text"]
        
        # summarizer ëª¨ë“ˆì˜ í•¨ìˆ˜ í˜¸ì¶œ (ì´ í•¨ìˆ˜ë“¤ì´ ì •ìƒ ì‘ë™í•œë‹¤ê³  ê°€ì •)
        summary = summarize_text(transcript) 
        script = generate_video_script(summary)
        
        return transcript, summary, script
    except Exception as e:
        st.error(f"ì˜¤ë””ì˜¤ ì „ì‚¬/ìš”ì•½/ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "", "", ""
    finally:
        if tmp_path and os.path.exists(tmp_path):
            os.remove(tmp_path) # ì„ì‹œ íŒŒì¼ ì‚­ì œ

if IS_LOCAL and st.button("ğŸ™ 5ì´ˆê°„ ë…¹ìŒí•˜ê¸°"):
    if st.session_state.model is None:
        st.warning("ë¨¼ì € ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”!")
    else:
        audio_np = record_audio(duration_sec=5)
        if audio_np is not None:
            wav_bytes = numpy_to_wav_bytes(audio_np)
            st.audio(wav_bytes, format="audio/wav")
            transcript, summary, script = transcribe_audio(st.session_state.model, wav_bytes)
            
            st.subheader("ğŸ“ ì „ì‚¬ ê²°ê³¼")
            st.write(transcript)
            st.subheader("ğŸ” ìš”ì•½")
            st.write(summary)
            st.subheader("ğŸ¬ ê°ì„± ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸")
            st.write(script)
            st.session_state["script"] = script
        else:
            st.error("ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")


uploaded_audio_file = st.file_uploader("ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼(.wav/.mp3)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["wav", "mp3"])
if uploaded_audio_file:
    if st.session_state.model is None:
        st.warning("ë¨¼ì € ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”!")
    else:
        st.audio(uploaded_audio_file, format=f"audio/{uploaded_audio_file.type.split('/')[-1]}")
        transcript, summary, script = transcribe_audio(st.session_state.model, uploaded_audio_file)
        
        st.subheader("ğŸ“ ì „ì‚¬ ê²°ê³¼")
        st.write(transcript)
        st.subheader("ğŸ” ìš”ì•½")
        st.write(summary)
        st.subheader("ğŸ¬ ê°ì„± ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸")
        st.write(script)
        st.session_state["script"] = script

# --- 4ï¸âƒ£ ì˜ìƒ ìƒì„± ---
st.header("4ï¸âƒ£ ì˜ìƒ ìƒì„±")

# ì„¸ì…˜ ìƒíƒœì—ì„œ í•„ìš”í•œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
prompt = st.session_state.get("video_prompt") # 2ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ì˜ìƒ í”„ë¡¬í”„íŠ¸
image_path = st.session_state.get("saved_image_path") # 1ë‹¨ê³„ì—ì„œ ì €ì¥ëœ ì•„ë°”íƒ€ ì´ë¯¸ì§€ ê²½ë¡œ
script = st.session_state.get("script") # 3ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ê°ì„± ìŠ¤í¬ë¦½íŠ¸

def create_video_from_text_and_image(full_prompt, image_path):
    """
    ì˜ìƒ ìƒì„± ë¡œì§ (í˜„ì¬ëŠ” ë”ë¯¸ í•¨ìˆ˜)
    ì‹¤ì œ êµ¬í˜„ ì‹œ D-ID, RunwayML ë“± ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ë™ í•„ìš”
    """
    st.info(f"ì˜ìƒ ìƒì„± ì¤‘...\n\nğŸ§¾ í”„ë¡¬í”„íŠ¸: {full_prompt}\nğŸ–¼ï¸ ì´ë¯¸ì§€ ê²½ë¡œ: {image_path}")
    # ì—¬ê¸°ì— ì‹¤ì œ ì˜ìƒ ìƒì„± API í˜¸ì¶œ ë˜ëŠ” ë¡œì§ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
    # ì˜ˆ: D-ID API í˜¸ì¶œ, ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í•˜ì—¬ ì˜ìƒ ìƒì„±
    st.success("âœ… (ì˜ˆì‹œ) ì˜ìƒ ìƒì„± ì™„ë£Œ! ì‹¤ì œ ì˜ìƒ ìƒì„± ê¸°ëŠ¥ì€ ì¶”í›„ ì—°ë™ë©ë‹ˆë‹¤.")


# ì˜ìƒ ìƒì„± ë²„íŠ¼ í™œì„±í™” ì¡°ê±´
can_create_video = False
if prompt and image_path and os.path.exists(image_path) and script:
    st.image(image_path, caption="ğŸ¨ ìµœì¢… ì˜ìƒìš© ì–¼êµ´ ì´ë¯¸ì§€", use_container_width=True)
    full_prompt = f"{prompt}\n\nğŸ—£ï¸ ê°ì„± ëŒ€ì‚¬:\n{script}"
    st.info(f"ğŸ§¾ ì˜ìƒ í”„ë¡¬í”„íŠ¸:\n\n{full_prompt}")
    can_create_video = True
else:
    st.warning("âš ï¸ ì˜ìƒ ìƒì„±ì„ ìœ„í•´ ì´ë¦„/ìƒë…„ ì…ë ¥, ì–¼êµ´ ì‚¬ì§„, ìŒì„± ë“±ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    missing_items = []
    if not prompt: missing_items.append("ì˜ìƒ í”„ë¡¬í”„íŠ¸")
    if not image_path or not os.path.exists(image_path): missing_items.append("ì•„ë°”íƒ€ ì´ë¯¸ì§€")
    if not script: missing_items.append("ê°ì„± ìŠ¤í¬ë¦½íŠ¸ (ìŒì„± ì „ì‚¬/ìš”ì•½)")
    if missing_items: # ëˆ„ë½ëœ í•­ëª©ì´ ìˆì„ ë•Œë§Œ í‘œì‹œ
        st.info(f"ëˆ„ë½ëœ í•­ëª©: {', '.join(missing_items)}")


if can_create_video:
    if st.button("ğŸï¸ ì˜ìƒ ë§Œë“¤ê¸°"):
        with st.spinner("ì˜ìƒì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
            create_video_from_text_and_image(full_prompt, image_path)