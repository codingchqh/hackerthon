# app.py
import streamlit as st
from PIL import Image
import io
import numpy as np
import wave
import whisper
import tempfile
import os
import datetime
import platform
from datetime import datetime

from camera.face_capture import extract_face
from summarizer.gpt_summarizer import summarize_text, generate_video_script

# --- í”Œë«í¼ í™•ì¸ (ë¡œì»¬/í´ë¼ìš°ë“œ êµ¬ë¶„) ---
IS_LOCAL = platform.system() != "Linux"
if IS_LOCAL:
    import sounddevice as sd

# --- Whisper ëª¨ë¸ ìºì‹œ ë¡œë“œ ---
@st.cache_resource
def load_model():
    return whisper.load_model("base")

model = load_model()

# --- ì˜¤ë””ì˜¤ ë…¹ìŒ í•¨ìˆ˜ (ë¡œì»¬ ì „ìš©) ---
def record_audio(duration_sec=5, fs=16000, device=None):
    if not IS_LOCAL:
        st.error("âš ï¸ ì´ ê¸°ëŠ¥ì€ ë¡œì»¬ í™˜ê²½ì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤. Streamlit Cloudì—ì„œëŠ” ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        return None
    st.info(f"{duration_sec}ì´ˆê°„ ë…¹ìŒ ì‹œì‘...")
    audio = sd.rec(int(duration_sec * fs), samplerate=fs, channels=1, dtype='int16', device=device)
    sd.wait()
    st.success("ë…¹ìŒ ì™„ë£Œ!")
    return audio.flatten()

# --- NumPy ë°°ì—´ -> WAV ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼ ë³€í™˜ ---
def numpy_to_wav_bytes(audio_np, fs=16000):
    buffer = io.BytesIO()
    with wave.open(buffer, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(fs)
        wf.writeframes(audio_np.tobytes())
    buffer.seek(0)
    return buffer

# --- Whisper ì „ì‚¬ ë° ìš”ì•½/ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ---
def transcribe_audio(model, wav_io):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
        tmp_file.write(wav_io.read())
        tmp_path = tmp_file.name

    result = model.transcribe(tmp_path)
    os.remove(tmp_path)

    transcript = result["text"]
    summary = summarize_text(transcript)
    script = generate_video_script(summary)

    return transcript, summary, script

# --- ë‚˜ì´ ê³„ì‚° í•¨ìˆ˜ ---
def get_age(birth_year):
    current_year = datetime.now().year
    return current_year - birth_year

# --- ì˜ìƒ ìƒì„± í•¨ìˆ˜ (ì˜ˆì‹œ) ---
def create_video_from_text_and_image(prompt, image_path):
    # ì—¬ê¸°ì— ì‹¤ì œ ì˜ìƒ ìƒì„± ë¡œì§ì„ êµ¬í˜„í•˜ê±°ë‚˜ ì™¸ë¶€ API í˜¸ì¶œ ê°€ëŠ¥
    st.info(f"ì˜ìƒ ìƒì„± ì¤‘...\n\nğŸ§¾ í”„ë¡¬í”„íŠ¸: {prompt}\nğŸ–¼ï¸ ì´ë¯¸ì§€: {image_path}")
    # ì˜ˆì‹œìš©ìœ¼ë¡œ íŒŒì¼ ê²½ë¡œë§Œ ì¶œë ¥
    st.success("âœ… (ì˜ˆì‹œ) ì˜ìƒ ìƒì„± ì™„ë£Œ!")

# --- Streamlit ì„¤ì • ---
st.set_page_config(page_title="AI ì•„ë°”íƒ€ + ìŒì„± ë…¹ìŒ & ì „ì‚¬", layout="centered")
st.title("ğŸ“¸ AI ì•„ë°”íƒ€ ìƒì„± + ğŸ¤ ìŒì„± ë…¹ìŒ & Whisper ì „ì‚¬")

# --- 1ï¸âƒ£ ì‚¬ì§„ ì´¬ì˜ ë° ì–¼êµ´ ì¶”ì¶œ ---
st.header("1ï¸âƒ£ ì‚¬ì§„ ì´¬ì˜ ë° ì–¼êµ´ ì¶”ì¶œ")
image_file = st.camera_input("ì•„ë°”íƒ€ìš© ì‚¬ì§„ì„ ì°ì–´ë³´ì„¸ìš”")

if image_file:
    image_pil = Image.open(image_file)
    st.image(image_pil, caption="ğŸ“· ì´¬ì˜ëœ ì›ë³¸ ì´ë¯¸ì§€", use_container_width=True)

    face_img = extract_face(image_pil)
    if face_img is None:
        st.error("ğŸ˜¢ ì–¼êµ´ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    else:
        st.image(face_img, caption="âœ‚ï¸ ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ", width=256)
        st.write("ğŸ¨ AI ì•„ë°”íƒ€ ìƒì„± (ì„ì‹œ ë²„ì „)")
        avatar_img = face_img
        st.image(avatar_img, caption="ğŸ–¼ï¸ ìƒì„±ëœ AI ì•„ë°”íƒ€", use_container_width=True)

        save_dir = "image"  # ìƒëŒ€ê²½ë¡œë¡œ ë³€ê²½í•´ë„ ì¢‹ìŒ
        os.makedirs(save_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_path = os.path.join(save_dir, f"face_{timestamp}.jpg")
        avatar_img.save(save_path)
        st.success(f"ì–¼êµ´ ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\n{save_path}")

        # âœ… ì–¼êµ´ ì´ë¯¸ì§€ ê²½ë¡œ ì €ì¥
        st.session_state["saved_image_path"] = save_path

# --- 1.5ï¸âƒ£ ì´ë¦„ ë° ìƒë…„ â†’ í”„ë¡¬í”„íŠ¸ ìƒì„± ---
st.title("ë§ì¶¤í˜• ì˜ìƒ ìƒì„±ê¸° ğŸ¬")

name = st.text_input("ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")
birth_year = st.number_input("íƒœì–´ë‚œ ë…„ë„ë¥¼ ì…ë ¥í•˜ì„¸ìš”", min_value=1900, max_value=datetime.now().year, step=1)

if st.button("ë‚˜ì´ë³„ ì˜ìƒ í”„ë¡¬í”„íŠ¸ ìƒì„±"):
    if not name:
        st.warning("ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        age = get_age(birth_year)
        st.write(f"ì•ˆë…•í•˜ì„¸ìš”, {name}ë‹˜! í˜„ì¬ ë‚˜ì´ëŠ” {age}ì„¸ ì…ë‹ˆë‹¤.")

        # ë‚˜ì´ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        if age < 20:
            prompt = f"{name}ë‹˜ì˜ ì–´ë¦° ì‹œì ˆ ëª¨ìŠµì„ ë‹´ì€ ë°ê³  í™œê¸°ì°¬ ì˜ìƒ"
        elif age < 40:
            prompt = f"{name}ë‹˜ì˜ ì Šê³  ì—­ë™ì ì¸ ëª¨ìŠµì„ ë‹´ì€ ì„¸ë ¨ëœ ì˜ìƒ"
        elif age < 60:
            prompt = f"{name}ë‹˜ì˜ ì„±ìˆ™í•˜ê³  ì•ˆì •ëœ ëª¨ìŠµì„ ë‹´ì€ ë”°ëœ»í•œ ì˜ìƒ"
        else:
            prompt = f"{name}ë‹˜ì˜ ì¸ìƒì˜ ì§€í˜œì™€ ê²½í—˜ì„ ë‹´ì€ ê°ë™ì ì¸ ì˜ìƒ"

        st.write("ğŸ§¾ ìƒì„±ëœ ì˜ìƒ í”„ë¡¬í”„íŠ¸:")
        st.info(prompt)

        # ì–¼êµ´ ì´ë¯¸ì§€ ì¶œë ¥ + ì˜ìƒ ìƒì„± ë²„íŠ¼
        image_path = st.session_state.get("saved_image_path", None)
        if image_path and os.path.exists(image_path):
            st.image(image_path, caption="ğŸ¨ ìƒì„±ëœ ì–¼êµ´ ì´ë¯¸ì§€", use_container_width=True)
            if st.button("ğŸï¸ ì˜ìƒ ë§Œë“¤ê¸°"):
                create_video_from_text_and_image(prompt, image_path)
        else:
            st.warning("âš ï¸ ì–¼êµ´ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì§„ì„ ë¨¼ì € ì°ì–´ ì£¼ì„¸ìš”.")

# --- 2ï¸âƒ£ ìŒì„± ë…¹ìŒ ë° Whisper ì „ì‚¬ ---
st.header("2ï¸âƒ£ ìŒì„± ë…¹ìŒ ë° Whisper ì „ì‚¬")

if IS_LOCAL and st.button("ğŸ™ 5ì´ˆê°„ ë…¹ìŒí•˜ê¸°"):
    audio_np = record_audio(duration_sec=5)
    if audio_np is not None:
        wav_bytes = numpy_to_wav_bytes(audio_np)
        st.audio(wav_bytes, format="audio/wav")
        transcript, summary, script = transcribe_audio(model, wav_bytes)
        st.subheader("ğŸ“ ì „ì‚¬ ê²°ê³¼")
        st.write(transcript)
        st.subheader("ğŸ” ìš”ì•½")
        st.write(summary)
        st.subheader("ğŸ¬ ê°ì„± ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸")
        st.write(script)

# --- íŒŒì¼ ì—…ë¡œë“œ (Streamlit Cloudìš©) ---
uploaded_file = st.file_uploader("ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼(.wav/.mp3)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["wav", "mp3"])

if uploaded_file is not None:
    st.audio(uploaded_file, format="audio/wav")
    transcript, summary, script = transcribe_audio(model, uploaded_file)
    st.subheader("ğŸ“ ì „ì‚¬ ê²°ê³¼")
    st.write(transcript)
    st.subheader("ğŸ” ìš”ì•½")
    st.write(summary)
    st.subheader("ğŸ¬ ê°ì„± ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸")
    st.write(script)
