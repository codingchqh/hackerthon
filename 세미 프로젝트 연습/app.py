import streamlit as st
from PIL import Image
import io
import numpy as np
import wave
import whisper
import tempfile
import os
import platform
from datetime import datetime
from avatar_create.avatar_generator import generate_avatar


from camera.face_capture import extract_face
from summarizer.gpt_summarizer import summarize_text, generate_video_script

# --- í”Œë«í¼ í™•ì¸ (ë¡œì»¬/í´ë¼ìš°ë“œ êµ¬ë¶„) ---
IS_LOCAL = platform.system() != "Linux"
if IS_LOCAL:
    import sounddevice as sd

# --- ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜ (ìºì‹œ ì œê±°) ---
def load_model():
    return whisper.load_model("base")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "model" not in st.session_state:
    st.session_state.model = None

# --- UI ì‹œì‘ ---
st.set_page_config(page_title="AI ì•„ë°”íƒ€ + Whisper ì „ì‚¬", layout="centered")
st.title("ğŸ“¸ AI ì•„ë°”íƒ€ ìƒì„± + ğŸ¤ ìŒì„± ì „ì‚¬ & ì˜ìƒ ìƒì„±")

# --- 0ï¸âƒ£ ëª¨ë¸ ë¡œë“œ ë²„íŠ¼ ---
if st.session_state.model is None:
    if st.button("ëª¨ë¸ ë¡œë“œí•˜ê¸°"):
        with st.spinner("ëª¨ë¸ì„ ë¡œë”©ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            st.session_state.model = load_model()
        st.success("âœ… ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
else:
    st.info("âœ… ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")

# --- ë””ë ‰í† ë¦¬ ìƒì„± ---
os.makedirs("image", exist_ok=True)

# --- 1ï¸âƒ£ ì‚¬ì§„ ì…ë ¥: ì¹´ë©”ë¼ ì´¬ì˜ ë˜ëŠ” ì´ë¯¸ì§€ ì—…ë¡œë“œ ---
st.header("1ï¸âƒ£ ì–¼êµ´ ì´ë¯¸ì§€ ì…ë ¥ ë° ì•„ë°”íƒ€ ìƒì„±")

# íƒ­ìœ¼ë¡œ ì„ íƒ (ì´¬ì˜ ë˜ëŠ” ì—…ë¡œë“œ)
tab1, tab2 = st.tabs(["ğŸ“¸ ì¹´ë©”ë¼ ì´¬ì˜", "ğŸ–¼ï¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ"])

image_pil = None

with tab1:
    image_file = st.camera_input("ì•„ë°”íƒ€ìš© ì‚¬ì§„ì„ ì°ì–´ë³´ì„¸ìš”")
    if image_file:
        image_pil = Image.open(image_file)
        st.image(image_pil, caption="ğŸ“· ì´¬ì˜ëœ ì›ë³¸ ì´ë¯¸ì§€", use_container_width=True)

with tab2:
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (jpg/png)", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        image_pil = Image.open(uploaded_file)
        st.image(image_pil, caption="ğŸ–¼ï¸ ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)

# ì–¼êµ´ ì¶”ì¶œ ë° ì•„ë°”íƒ€ ìƒì„±
if image_pil:
    face_img = extract_face(image_pil)
    if face_img is None:
        st.error("ğŸ˜¢ ì–¼êµ´ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‹œë„í•´ì£¼ì„¸ìš”.")
    else:
        st.image(face_img, caption="âœ‚ï¸ ì¶”ì¶œëœ ì–¼êµ´", width=256)

        # âœ… ì•„ë°”íƒ€ ìƒì„±
        avatar_img = generate_avatar(face_img)
        st.image(avatar_img, caption="ğŸ–¼ï¸ ìƒì„±ëœ AI ì•„ë°”íƒ€", use_container_width=True)

        # âœ… ì €ì¥ ê²½ë¡œ êµ¬ì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_path = f"image/avatar_{timestamp}.jpg"
        avatar_img.save(save_path)
        st.success(f"âœ… ì•„ë°”íƒ€ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")

        # âœ… ì„¸ì…˜ ìƒíƒœ ì €ì¥
        st.session_state["saved_image_path"] = save_path

# --- 2ï¸âƒ£ ì´ë¦„/ìƒë…„ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ---
st.title("ë§ì¶¤í˜• ì˜ìƒ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ğŸ¬")

name = st.text_input("ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")
birth_year = st.number_input("íƒœì–´ë‚œ ë…„ë„ë¥¼ ì…ë ¥í•˜ì„¸ìš”", min_value=1900, max_value=datetime.now().year, step=1)

def get_age(birth_year):
    current_year = datetime.now().year
    return current_year - birth_year

if st.button("í”„ë¡¬í”„íŠ¸ ìƒì„±"):
    if not name:
        st.warning("ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        age = get_age(birth_year)
        st.write(f"ì•ˆë…•í•˜ì„¸ìš”, {name}ë‹˜! í˜„ì¬ ë‚˜ì´ëŠ” {age}ì„¸ì…ë‹ˆë‹¤.")

        if age < 20:
            prompt = f"{name}ë‹˜ì˜ ì–´ë¦° ì‹œì ˆ ëª¨ìŠµì„ ë‹´ì€ ë°ê³  í™œê¸°ì°¬ ì˜ìƒ"
        elif age < 40:
            prompt = f"{name}ë‹˜ì˜ ì Šê³  ì—­ë™ì ì¸ ëª¨ìŠµì„ ë‹´ì€ ì„¸ë ¨ëœ ì˜ìƒ"
        elif age < 60:
            prompt = f"{name}ë‹˜ì˜ ì„±ìˆ™í•˜ê³  ì•ˆì •ëœ ëª¨ìŠµì„ ë‹´ì€ ë”°ëœ»í•œ ì˜ìƒ"
        else:
            prompt = f"{name}ë‹˜ì˜ ì¸ìƒì˜ ì§€í˜œì™€ ê²½í—˜ì„ ë‹´ì€ ê°ë™ì ì¸ ì˜ìƒ"

        st.info(prompt)
        st.session_state["video_prompt"] = prompt

# --- 3ï¸âƒ£ ìŒì„± ë…¹ìŒ ë° Whisper ì „ì‚¬ ---

def record_audio(duration_sec=5, fs=16000, device=None):
    if not IS_LOCAL:
        st.error("âš ï¸ ë¡œì»¬ì—ì„œë§Œ ë…¹ìŒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        return None
    st.info(f"{duration_sec}ì´ˆê°„ ë…¹ìŒ ì¤‘...")
    audio = sd.rec(int(duration_sec * fs), samplerate=fs, channels=1, dtype='int16', device=device)
    sd.wait()
    st.success("ë…¹ìŒ ì™„ë£Œ!")
    return audio.flatten()

def numpy_to_wav_bytes(audio_np, fs=16000):
    buffer = io.BytesIO()
    with wave.open(buffer, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(fs)
        wf.writeframes(audio_np.tobytes())
    buffer.seek(0)
    return buffer

def transcribe_audio(model, wav_io):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
        tmp_file.write(wav_io.read())
        tmp_path = tmp_file.name

    try:
        result = model.transcribe(tmp_path)
    finally:
        os.remove(tmp_path)

    transcript = result["text"]
    summary = summarize_text(transcript)
    script = generate_video_script(summary)
    return transcript, summary, script

if IS_LOCAL and st.button("ğŸ™ 5ì´ˆê°„ ë…¹ìŒí•˜ê¸°"):
    if st.session_state.model is None:
        st.warning("ë¨¼ì € ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”!")
    else:
        audio_np = record_audio(duration_sec=5)
        if audio_np is not None:
            wav_bytes = numpy_to_wav_bytes(audio_np)
            st.audio(wav_bytes, format="audio/wav")
            transcript, summary, script = transcribe_audio(st.session_state.model, wav_bytes)
            st.subheader("ğŸ“ ì „ì‚¬ ê²°ê³¼")
            st.write(transcript)
            st.subheader("ğŸ” ìš”ì•½")
            st.write(summary)
            st.subheader("ğŸ¬ ê°ì„± ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸")
            st.write(script)
            st.session_state["script"] = script

uploaded_file = st.file_uploader("ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼(.wav/.mp3)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["wav", "mp3"])

if uploaded_file:
    if st.session_state.model is None:
        st.warning("ë¨¼ì € ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”!")
    else:
        st.audio(uploaded_file, format="audio/wav")
        transcript, summary, script = transcribe_audio(st.session_state.model, uploaded_file)
        st.subheader("ğŸ“ ì „ì‚¬ ê²°ê³¼")
        st.write(transcript)
        st.subheader("ğŸ” ìš”ì•½")
        st.write(summary)
        st.subheader("ğŸ¬ ê°ì„± ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸")
        st.write(script)
        st.session_state["script"] = script

# --- 4ï¸âƒ£ ì˜ìƒ ìƒì„± ---
st.header("4ï¸âƒ£ ì˜ìƒ ìƒì„±")

prompt = st.session_state.get("video_prompt", None)
image_path = st.session_state.get("saved_image_path", None)
script = st.session_state.get("script", None)

def create_video_from_text_and_image(full_prompt, image_path):
    st.info(f"ì˜ìƒ ìƒì„± ì¤‘...\n\nğŸ§¾ í”„ë¡¬í”„íŠ¸: {full_prompt}\nğŸ–¼ï¸ ì´ë¯¸ì§€: {image_path}")
    st.success("âœ… (ì˜ˆì‹œ) ì˜ìƒ ìƒì„± ì™„ë£Œ!")

if prompt and image_path and os.path.exists(image_path):
    st.image(image_path, caption="ğŸ¨ ìµœì¢… ì˜ìƒìš© ì–¼êµ´ ì´ë¯¸ì§€", use_container_width=True)

    if script:
        full_prompt = f"{prompt}\n\nğŸ—£ï¸ ê°ì„± ëŒ€ì‚¬:\n{script}"
    else:
        full_prompt = prompt

    st.info(f"ğŸ§¾ ì˜ìƒ í”„ë¡¬í”„íŠ¸:\n\n{full_prompt}")

    if st.button("ğŸï¸ ì˜ìƒ ë§Œë“¤ê¸°"):
        create_video_from_text_and_image(full_prompt, image_path)
else:
    st.warning("âš ï¸ ì˜ìƒ ìƒì„±ì„ ìœ„í•´ ì´ë¦„, ìƒë…„, ì–¼êµ´ ì‚¬ì§„, ìŒì„± ë“±ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
