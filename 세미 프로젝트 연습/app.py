import streamlit as st
from PIL import Image
import io
import numpy as np
import wave
import tempfile
import os
import platform
import openai
from datetime import datetime

from summarizer.gpt_summarizer import analyze_transcript_for_completeness, create_final_video_prompt
# --- ë‹¤ë¥¸ íŒŒì´ì¬ íŒŒì¼ì—ì„œ í•µì‹¬ ë¡œì§ import ---


# --------------------------------------------------------------------------
# --- 0. ì´ˆê¸° ì„¤ì •: í”Œë«í¼ í™•ì¸, í´ë” ìƒì„± ---
# --------------------------------------------------------------------------

# í”Œë«í¼ í™•ì¸ (ë¡œì»¬ í™˜ê²½ì—ì„œë§Œ ë§ˆì´í¬ ë…¹ìŒ ê¸°ëŠ¥ í™œì„±í™”)
IS_LOCAL = platform.system() != "Linux"
if IS_LOCAL:
    try:
        import sounddevice as sd
    except Exception as e:
        # st.error(f"Sounddevice ë¡œë“œ ì‹¤íŒ¨: {e}") # ì‚¬ìš©ìì—ê²Œ ë„ˆë¬´ ê¸°ìˆ ì ì¸ ì˜¤ë¥˜ëŠ” ìˆ¨ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        IS_LOCAL = False

# ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„±
os.makedirs("image_storage", exist_ok=True)


# --------------------------------------------------------------------------
# --- 1. í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ì˜¤ë””ì˜¤, ì•„ë°”íƒ€, ë¹„ë””ì˜¤ ë“±) ---
# --------------------------------------------------------------------------

# --- Audio Processing Functions ---
def record_audio(duration_sec=10, fs=16000):
    """ì§€ì •ëœ ì‹œê°„ ë™ì•ˆ ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ë…¹ìŒí•©ë‹ˆë‹¤."""
    st.info(f"{duration_sec}ì´ˆê°„ ì¸í„°ë·° ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    try:
        audio_data = sd.rec(int(duration_sec * fs), samplerate=fs, channels=1, dtype='int16')
        sd.wait()
        st.success("ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return audio_data.flatten()
    except Exception as e:
        st.error(f"ì˜¤ë””ì˜¤ ë…¹ìŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë§ˆì´í¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\nì˜¤ë¥˜: {e}")
        return None

def numpy_to_wav_bytes(audio_np, fs=16000):
    """Numpy ì˜¤ë””ì˜¤ ë°°ì—´ì„ WAV í˜•ì‹ì˜ BytesIO ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    buffer = io.BytesIO()
    with wave.open(buffer, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2) # 16-bit
        wf.setframerate(fs)
        wf.writeframes(audio_np.tobytes())
    buffer.seek(0)
    return buffer

def transcribe_audio_from_bytes(audio_bytes_io):
    """BytesIO ì˜¤ë””ì˜¤ ê°ì²´ë¥¼ Whisper APIë¡œ ì „ì‚¬í•©ë‹ˆë‹¤."""
    tmp_path = None
    try:
        # BytesIO ê°ì²´ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ APIì— ì „ë‹¬
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_bytes_io.getvalue())
            tmp_path = tmp_file.name

        with open(tmp_path, "rb") as audio_file:
            # openai ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìµœì‹  ë²„ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
            transcript = openai.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="text"
            )
        return str(transcript)
    except Exception as e:
        st.error(f"ìŒì„± ì „ì‚¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""
    finally:
        if tmp_path and os.path.exists(tmp_path):
            os.remove(tmp_path)


# --- DUMMY Functions (ì‹¤ì œ ì„œë¹„ìŠ¤ ì—°ë™ì´ í•„ìš”í•œ ë¶€ë¶„) ---
def extract_face(image_pil):
    """DUMMY: ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ë¶€ë¶„ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    # ì‹¤ì œ êµ¬í˜„ ì‹œ: OpenCV, dlib ë“±ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
    st.info("DUMMY: ì–¼êµ´ ì¶”ì¶œ ë¡œì§ ì‹¤í–‰ ì¤‘...")
    return image_pil.resize((256, 256))

def generate_avatar(face_image):
    """DUMMY: AI ì•„ë°”íƒ€ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    # ì‹¤ì œ êµ¬í˜„ ì‹œ: Stable Diffusion, Midjourney API ë“± ì—°ë™
    st.info("DUMMY: AI ì•„ë°”íƒ€ ìƒì„± ë¡œì§ ì‹¤í–‰ ì¤‘...")
    return Image.new('RGB', (512, 512), color = 'blue')

def create_video_from_text_and_image(prompt, image_path):
    """DUMMY: ìµœì¢… í”„ë¡¬í”„íŠ¸ì™€ ì´ë¯¸ì§€ë¡œ ì˜ìƒì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    # ì‹¤ì œ êµ¬í˜„ ì‹œ: D-ID, RunwayML, Pika Labs ë“± ì˜ìƒ ìƒì„± AI API ì—°ë™
    st.info(f"DUMMY: ì˜ìƒ ìƒì„± ì¤‘...\n- í”„ë¡¬í”„íŠ¸: {prompt[:100]}...\n- ì´ë¯¸ì§€ ê²½ë¡œ: {image_path}")
    st.success("âœ… (ì˜ˆì‹œ) ì˜ìƒ ìƒì„± ì™„ë£Œ!")
    st.video("https://www.youtube.com/watch?v=dQw4w9WgXcQ") # ì˜ˆì‹œ ë¹„ë””ì˜¤


# --- ì˜ˆì‹œ ì§ˆë¬¸ ëª©ë¡ ---
interview_questions = {
    "ìš°ë¦¬ì˜ í‰ë²”í•˜ì§€ë§Œ ì†Œì¤‘í•œ ì¼ìƒ": ["ê°€ì¡±ê³¼ í•¨ê»˜í•˜ëŠ” ì•„ì¹¨ ì‹ì‚¬ ì‹œê°„ì€ ì–´ë–¤ ëª¨ìŠµì¸ê°€ìš”?", "ìµœê·¼ì— í•¨ê»˜ ì‚°ì±…í•˜ë©° ë‚˜ëˆˆ ì†Œì†Œí•œ ëŒ€í™”ê°€ ìˆë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”.", "ìš°ë¦¬ ê°€ì¡±ë§Œì˜ ìê¸° ì „ ìŠµê´€ì´ë‚˜ ì£¼ë§ì„ ë³´ë‚´ëŠ” íŠ¹ë³„í•œ ë°©ë²•ì´ ìˆë‚˜ìš”?"],
    "í•¨ê»˜ ë– ë‚¬ë˜ ì¦ê±°ìš´ ì—¬í–‰ì˜ ì¶”ì–µ": ["ì§€ê¸ˆê¹Œì§€ ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ê°€ì¡± ì—¬í–‰ì€ ì–´ë””ì˜€ë‚˜ìš”? ì™œ ê·¸ê³³ì´ íŠ¹ë³„í–ˆë‚˜ìš”?", "ì—¬í–‰ì§€ì—ì„œ ê²ªì—ˆë˜ ê°€ì¥ ì¬ë¯¸ìˆëŠ” ì—í”¼ì†Œë“œë‚˜ ì˜ˆìƒì¹˜ ëª»í•œ ì‚¬ê±´ì´ ìˆì—ˆë‚˜ìš”?", "ì‚¬ì§„ì„ ë‹¤ì‹œ í¼ì³ë³´ê²Œ ë˜ëŠ”, ê°€ì¥ ë§ˆìŒì— ë“œëŠ” ì—¬í–‰ ì‚¬ì§„ì€ ë¬´ì—‡ì¸ê°€ìš”?"],
    "íŠ¹ë³„í•œ ë‚ ì˜ í–‰ë³µí–ˆë˜ ìˆœê°„ë“¤": ["ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ìƒì¼ì´ë‚˜ ê¸°ë…ì¼ì€ ì–¸ì œì˜€ë‚˜ìš”?", "ìš°ë¦¬ ê°€ì¡±ë§Œì´ ê°€ì§„ íŠ¹ë³„í•œ ëª…ì ˆ ì „í†µì´ ìˆë‹¤ë©´ ë¬´ì—‡ì¸ê°€ìš”?", "ì„œë¡œì—ê²Œ ì¤¬ë˜ ì„ ë¬¼ ì¤‘ ê°€ì¥ ê°ë™ì ì´ê±°ë‚˜ ì¬ë¯¸ìˆì—ˆë˜ ê²ƒì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?"],
    "ì•„ì´ë“¤ì˜ ì‚¬ë‘ìŠ¤ëŸ¬ìš´ ì„±ì¥ ê¸°ë¡": ["ìë…€ê°€ íƒœì–´ë‚¬ì„ ë•Œ, í˜¹ì€ ì²˜ìŒìœ¼ë¡œ 'ì—„ë§ˆ/ì•„ë¹ 'ë¼ê³  ë¶ˆë €ì„ ë•Œì˜ ê¸°ë¶„ì´ ì–´ë• ë‚˜ìš”?", "í•™ì°½ ì‹œì ˆ, ê°€ì¥ ìë‘ìŠ¤ëŸ¬ì› ë˜ ìˆœê°„ì´ë‚˜ í° ë„ì „ì„ í–ˆë˜ ê¸°ì–µì´ ìˆë‚˜ìš”?", "ë¶€ëª¨ë‹˜ê»˜ì„œëŠ” ìë…€ê°€ ì„±ì¥í•˜ëŠ” ëª¨ìŠµì„ ë³´ë©° ì–¸ì œê°€ ê°€ì¥ ëŒ€ê²¬í•˜ê³  ë¿Œë“¯í–ˆë‚˜ìš”?"],
    "ë‹¤ì‹œ ë´ë„ ì›ƒìŒì´ ë‚˜ëŠ” ìš°ë¦¬ ê°€ì¡±ì˜ ì¬ë¯¸ìˆëŠ” ìˆœê°„": ["ìš°ë¦¬ ê°€ì¡± êµ¬ì„±ì›ë“¤ë§Œ ì•„ëŠ” ì„œë¡œì˜ ì¬ë¯¸ìˆëŠ” ìŠµê´€ì´ë‚˜ ë²„ë¦‡ì´ ìˆë‚˜ìš”?", "ìƒê°ë§Œ í•´ë„ ì›ƒìŒì´ ë‚˜ëŠ” ìš°ë¦¬ ê°€ì¡±ì˜ 'í‘ì—­ì‚¬'ë‚˜ ì¬ë¯¸ìˆëŠ” ì‹¤ìˆ˜ë‹´ì´ ìˆë‹¤ë©´?", "ê°€ì¥ ì„±ê³µì ì´ì—ˆë˜ (ë˜ëŠ” ì™„ì „íˆ ì‹¤íŒ¨í–ˆë˜) ê°€ì¡± ì¥ë‚œì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?"],
    "ì„œë¡œì—ê²Œ ì „í•˜ëŠ” ì‚¬ë‘ê³¼ ê°ì‚¬ì˜ ë©”ì‹œì§€": ["ê°€ì¡±ì´ì–´ì„œ ê°€ì¥ í˜ì´ ë˜ì—ˆë˜ ìˆœê°„ì€ ì–¸ì œì˜€ë‚˜ìš”?", "ì„œë¡œì—ê²Œ í‰ì†Œì— ì‘¥ìŠ¤ëŸ¬ì›Œì„œ í•˜ì§€ ëª»í–ˆë˜ ê³ ë§ˆìš´ ë§ˆìŒì„ í‘œí˜„í•´ì£¼ì„¸ìš”.", "ì•ìœ¼ë¡œ ìš°ë¦¬ ê°€ì¡±ì´ í•¨ê»˜ ì´ë£¨ê³  ì‹¶ì€ ê¿ˆì´ë‚˜ ì†Œë§ì´ ìˆë‹¤ë©´ ë¬´ì—‡ì¸ê°€ìš”?"]
}

# --------------------------------------------------------------------------
# --- 2. Streamlit UI ë° ìƒíƒœ ê´€ë¦¬ ---
# --------------------------------------------------------------------------

st.title("ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ê°€ì¡± ì´ì•¼ê¸° AI ì˜ìƒ ë§Œë“¤ê¸°")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
default_states = {
    "step": "select_theme", "family_name": "", "selected_theme": list(interview_questions.keys())[0],
    "saved_image_path": None, "transcript": "", "final_prompt": None,
}
for key, value in default_states.items():
    if key not in st.session_state:
        st.session_state[key] = value

# --- ë‹¨ê³„ë³„ UI ë Œë”ë§ ---

# 1ë‹¨ê³„: í…Œë§ˆ ì„ íƒ
if st.session_state.step == "select_theme":
    st.header("1ë‹¨ê³„: ì˜ìƒ í…Œë§ˆ ì •í•˜ê¸°")
    st.session_state.family_name = st.text_input("ê°€ì¡±ì˜ í˜¸ì¹­ì„ ì…ë ¥í•˜ì„¸ìš”", value=st.session_state.family_name, placeholder="ì˜ˆ: ì‚¬ë‘í•˜ëŠ” ìš°ë¦¬ ê°€ì¡±")
    themes = list(interview_questions.keys())
    st.session_state.selected_theme = st.radio("ì–´ë–¤ í…Œë§ˆì˜ ì˜ìƒì„ ë§Œë“¤ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?", themes, key="theme_radio")
    
    if st.button("ë‹¤ìŒ ë‹¨ê³„ë¡œ: ì–¼êµ´ ì‚¬ì§„ ì…ë ¥ â–¶ï¸", type="primary"):
        if not st.session_state.family_name:
            st.warning("ê°€ì¡±ì˜ í˜¸ì¹­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!");
        else:
            st.session_state.step = "capture_avatar"; st.rerun()

# 2ë‹¨ê³„: ì•„ë°”íƒ€ ìƒì„±
elif st.session_state.step == "capture_avatar":
    st.header("2ë‹¨ê³„: ì˜ìƒì— ì‚¬ìš©í•  ì–¼êµ´ ì‚¬ì§„ ì…ë ¥")
    image_pil = None
    if IS_LOCAL:
        tab1, tab2 = st.tabs(["ğŸ“¸ ì¹´ë©”ë¼ ì´¬ì˜", "ğŸ–¼ï¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ"])
        with tab1: image_file = st.camera_input("ì•„ë°”íƒ€ìš© ì‚¬ì§„ì„ ì°ì–´ë³´ì„¸ìš”");
        with tab2: uploaded_file = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"]);
    else:
        st.warning("í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œëŠ” ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ì—…ë¡œë“œë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        uploaded_file = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"]);
        image_file = None
    
    if image_file: image_pil = Image.open(image_file)
    if uploaded_file: image_pil = Image.open(uploaded_file)

    if image_pil:
        with st.spinner("ì–¼êµ´ì„ ì¸ì‹í•˜ê³  ì•„ë°”íƒ€ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
            face_img = extract_face(image_pil)
            avatar_img = generate_avatar(face_img)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_path = f"image_storage/avatar_{timestamp}.jpg"
            avatar_img.save(save_path)
            st.session_state.saved_image_path = save_path
        st.success(f"ì•„ë°”íƒ€ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ!"); st.image(avatar_img, caption="ìƒì„±ëœ AI ì•„ë°”íƒ€")

    if st.session_state.saved_image_path:
        if st.button("ë‹¤ìŒ ë‹¨ê³„ë¡œ: ì¸í„°ë·° ì¤€ë¹„ â–¶ï¸", type="primary"):
            st.session_state.step = "show_questions"; st.rerun()

# 3ë‹¨ê³„: ì¸í„°ë·° ì§ˆë¬¸ í™•ì¸
elif st.session_state.step == "show_questions":
    st.header("3ë‹¨ê³„: ì¸í„°ë·° ì¤€ë¹„")
    st.info(f"**ì„ íƒ í…Œë§ˆ:** {st.session_state.selected_theme}")
    st.markdown("ì•„ë˜ ì§ˆë¬¸ë“¤ì„ ë³´ë©° ì–´ë–¤ ì´ì•¼ê¸°ë¥¼ í• ì§€ ììœ ë¡­ê²Œ êµ¬ìƒí•´ë³´ì„¸ìš”.")
    questions = interview_questions.get(st.session_state.selected_theme, [])
    for i, q in enumerate(questions): st.markdown(f"**Q{i+1}.** {q}")
    if st.button("âœ… ì¤€ë¹„ ì™„ë£Œ! ë…¹ìŒ ì‹œì‘í•˜ê¸° â–¶ï¸", type="primary"):
        st.session_state.step = "record_interview"; st.rerun()

# â­ï¸ 4ë‹¨ê³„: ëŒ€í™”í˜• ì¸í„°ë·° ë…¹ìŒ ë° ë¶„ì„ (ìƒˆë¡œìš´ ë¡œì§)
elif st.session_state.step == "record_interview":
    st.header("4ë‹¨ê³„: ëŒ€í™”í˜• ì¸í„°ë·° ì§„í–‰")
    st.info("ì•„ë˜ì—ì„œ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê°ê° ë…¹ìŒí•˜ì—¬ ì¸í„°ë·°ë¥¼ ì™„ì„±í•´ë³´ì„¸ìš”.")

    # --- í˜„ì¬ê¹Œì§€ì˜ Q&A ëª©ë¡ í‘œì‹œ ---
    if st.session_state.qa_list:
        st.subheader("âœ… ì™„ì„±ëœ ì§ˆë¬¸/ë‹µë³€ ëª©ë¡")
        for i, qa in enumerate(st.session_state.qa_list):
            with st.container(border=True):
                st.markdown(f"**Q{i+1}.** {qa['question']}")
                st.markdown(f"**A{i+1}.** {qa['answer']}")
        st.markdown("---")

    # --- ìƒˆë¡œìš´ Q&A ì¶”ê°€ ì¸í„°í˜ì´ìŠ¤ ---
    st.subheader("â• ìƒˆë¡œìš´ ì§ˆë¬¸ & ë‹µë³€ ì¶”ê°€í•˜ê¸°")

    # 1. ì§ˆë¬¸ ë…¹ìŒ ë‹¨ê³„
    if not st.session_state.current_question:
        st.markdown("**1. ë¨¼ì € ì§ˆë¬¸ì„ ë…¹ìŒí•˜ì„¸ìš”.**")
        if IS_LOCAL and st.button("ğŸ™ï¸ ì§ˆë¬¸ ë…¹ìŒí•˜ê¸° (5ì´ˆ)"):
            with st.spinner("ì§ˆë¬¸ì„ ë…¹ìŒí•˜ê³  ë³€í™˜ ì¤‘..."):
                audio_np = record_audio(duration_sec=5)
                if audio_np is not None:
                    wav_bytes = numpy_to_wav_bytes(audio_np)
                    st.session_state.current_question = transcribe_audio_from_bytes(wav_bytes)
                    st.rerun()

    # 2. ë‹µë³€ ë…¹ìŒ ë‹¨ê³„ (ì§ˆë¬¸ì´ ë…¹ìŒëœ í›„ì—ë§Œ ë³´ì„)
    else:
        st.success(f"**ë…¹ìŒëœ ì§ˆë¬¸:** {st.session_state.current_question}")
        st.markdown("**2. ì´ì œ ìœ„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ë…¹ìŒí•˜ì„¸ìš”.**")

        record_duration = st.slider("ë‹µë³€ ë…¹ìŒ ì‹œê°„(ì´ˆ)", 10, 180, 30, key="answer_duration")
        if IS_LOCAL and st.button(f"ğŸ¤ ë‹µë³€ ë…¹ìŒí•˜ê¸° ({record_duration}ì´ˆ)"):
            with st.spinner("ë‹µë³€ì„ ë…¹ìŒí•˜ê³  ë³€í™˜ ì¤‘..."):
                audio_np = record_audio(duration_sec=record_duration)
                if audio_np is not None:
                    wav_bytes = numpy_to_wav_bytes(audio_np)
                    answer = transcribe_audio_from_bytes(wav_bytes)
                    if answer:
                        # Q&A ìŒì„ ëª©ë¡ì— ì¶”ê°€í•˜ê³  ìƒíƒœ ì´ˆê¸°í™”
                        st.session_state.qa_list.append({
                            "question": st.session_state.current_question,
                            "answer": answer
                        })
                        st.session_state.current_question = ""
                        st.rerun()

    st.markdown("---")

    # --- ì „ì²´ ì¸í„°ë·° ë¶„ì„ ì‹œì‘ ---
    if st.session_state.qa_list:
        if st.button("âœ… ì¸í„°ë·° ì™„ë£Œ ë° ë¶„ì„ ì‹œì‘", type="primary"):
            with st.spinner("ì „ì²´ ì¸í„°ë·° ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                # Q&A ëª©ë¡ì„ í•˜ë‚˜ì˜ ëŒ€í™”ë¡ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                full_transcript = "\n\n".join([f"Interviewer Q: {qa['question']}\nAnswer: {qa['answer']}" for qa in st.session_state.qa_list])
                st.session_state.transcript = full_transcript # ë‚˜ì¤‘ì— í™•ì¸ìš©ìœ¼ë¡œ ì €ì¥

                analysis_result = analyze_transcript_for_completeness(full_transcript)
                if analysis_result.is_complete:
                    st.success("ì¶©ë¶„í•œ ë‚´ìš©ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤! ìµœì¢… í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                    final_prompt = create_final_video_prompt(st.session_state.family_name, st.session_state.selected_theme, full_transcript)
                    st.session_state.final_prompt = final_prompt
                else:
                    st.warning("âš ï¸ ì´ì•¼ê¸°ì˜ í•µì‹¬ ìš”ì†Œ(ëˆ„ê°€, ë¬´ì—‡ì„, ì™œ)ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.\n\nì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë” ì¶”ê°€í•˜ì—¬ ì´ì•¼ê¸°ë¥¼ êµ¬ì²´í™”í•´ì£¼ì„¸ìš”.")
            st.rerun() # ë¶„ì„ í›„ UI ì—…ë°ì´íŠ¸

    # ìµœì¢… í”„ë¡¬í”„íŠ¸ê°€ ìƒì„±ë˜ì—ˆë‹¤ë©´ í‘œì‹œí•˜ê³  ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™
    if st.session_state.final_prompt:
        st.success("âœ¨ AI í”„ë¡¬í”„íŠ¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.text_area("ìƒì„±ëœ ìµœì¢… AI í”„ë¡¬í”„íŠ¸", st.session_state.final_prompt, height=200)
        if st.button("ë‹¤ìŒ ë‹¨ê³„ë¡œ: ìµœì¢… í™•ì¸ â–¶ï¸"):
            st.session_state.step = "create_video"
            st.rerun()

# 5ë‹¨ê³„: ìµœì¢… í™•ì¸ ë° ì˜ìƒ ìƒì„±
elif st.session_state.step == "create_video":
    st.header("5ë‹¨ê³„: ìµœì¢… í™•ì¸ ë° ì˜ìƒ ìƒì„±")
    if st.session_state.saved_image_path and st.session_state.final_prompt:
        st.info("ì•„ë˜ ì •ë³´ë¡œ ìµœì¢… ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.")
        st.image(st.session_state.saved_image_path, caption="ğŸ¨ ìµœì¢… ì˜ìƒìš© ì•„ë°”íƒ€ ì´ë¯¸ì§€")
        st.text_area("ğŸ¬ ìµœì¢… ì˜ìƒ AI í”„ë¡¬í”„íŠ¸", st.session_state.final_prompt, height=200)
        if st.button("ğŸï¸ ì´ ë‚´ìš©ìœ¼ë¡œ ì˜ìƒ ë§Œë“¤ê¸°", type="primary"):
            with st.spinner("ì˜ìƒì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... (1~2ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                create_video_from_text_and_image(st.session_state.final_prompt, st.session_state.saved_image_path)
    else:
        st.error("ì˜ìƒ ìƒì„±ì— í•„ìš”í•œ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.")

# --- 'ì²˜ìŒìœ¼ë¡œ' ë²„íŠ¼ ---
if st.session_state.step != "select_theme":
    if st.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì£¼ì˜: ëª¨ë“  ì§„í–‰ìƒí™©ì´ ì‚¬ë¼ì§)
        st.session_state.step = "select_theme"
        st.session_state.family_name = ""
        st.session_state.saved_image_path = None
        st.session_state.transcript = ""
        st.session_state.final_prompt = None
        st.rerun()

